{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empathic Zoom\n",
    "\n",
    "Este script utiliza Selenium y la librería Deep Face para detectar las caras de los participantes en una reunión de Zoom web y mostrar las emociones de la reunión.\n",
    "\n",
    "Para ello, el script abrirá una sesión de Chrome automatizada con Selenium, accederá a la reunión de Zoom utilizando la URL proporcionada, y luego utilizará Deep Face para analizar las expresiones faciales de los participantes.\n",
    "\n",
    "*(Podemos llegar a usar OpenCV para analizar, ademas de las emociones, los gestos corporales)*\n",
    "\n",
    "*Por ejemplo:*\n",
    "- Detección de Movimiento y Postura: Utilizar algoritmos de visión por computadora para detectar el movimiento de las personas y su postura durante la reunión. Un aumento en el movimiento o cambios en la postura pueden indicar un mayor nivel de interés o participación.\n",
    "- Reconocimiento de Gestos Faciales: Analizar los gestos faciales de los participantes para detectar sonrisas, fruncir el ceño, miradas de atención, entre otros.\n",
    "- Participación en la Conversación: Analizar la participación verbal de las personas en la reunión, como la cantidad de tiempo que hablan, la frecuencia con la que hacen preguntas o comentarios, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librerías necesarias\n",
    "\n",
    "- pip install selenium\n",
    "- pip install deepface\n",
    "- pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Miner\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importamos librerias necesarias\n",
    "\n",
    "from selenium import webdriver\n",
    "from deepface import DeepFace\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Engagement Score: 1.0\n",
      "General Engagement Score: 1.0\n",
      "General Engagement Score: 1.0\n",
      "General Engagement Score: 1.0\n",
      "General Engagement Score: 1.0\n",
      "General Engagement Score: -1.0\n",
      "General Engagement Score: 0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def capture_screenshot(driver, filename='screenshot.png'):\n",
    "    driver.save_screenshot(filename)\n",
    "\n",
    "def analyze_emotion(image_path='screenshot.png'):\n",
    "    img = cv2.imread(image_path)\n",
    "    return DeepFace.analyze(img, actions=['emotion'])\n",
    "\n",
    "def compute_engagement(emotion_results):\n",
    "    engagement_scores = {\n",
    "        'happy': 1,\n",
    "        'surprise': 1,\n",
    "        'neutral': 0.5,\n",
    "        'sad': -1,\n",
    "        'angry': -1,\n",
    "        'fear': -1,\n",
    "        'disgust': -1\n",
    "    }\n",
    "    \n",
    "    total_score = 0\n",
    "    for res in emotion_results:\n",
    "        dominant_emotion = res.get('dominant_emotion')\n",
    "        total_score += engagement_scores.get(dominant_emotion, 0)\n",
    "    \n",
    "    return total_score / len(emotion_results)\n",
    "\n",
    "# Initialize WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "#driver.get(\"https://app.zoom.us/wc/6566777642/join?fromPWA=1&pwd=KkJzofviLFwL1w6rUxGpAWQTDov0Zo.1&_x_zm_rtaid=UsYTRJltSqCdGRR6BBx3eA.1716752925491.af11f663de2681fb904a8c586f897e03&_x_zm_rhtaid=198\")\n",
    "#time.sleep(60)  # Adjust based on when the meeting starts\n",
    "\n",
    "while True:\n",
    "    #capture_screenshot(driver)\n",
    "    emotion_result = analyze_emotion()\n",
    "    engagement_score = compute_engagement(emotion_result)\n",
    "    print(f\"General Engagement Score: {engagement_score}\")\n",
    "    time.sleep(20)  # Capture screenshot every minute\n",
    "\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
