{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empathic Zoom\n",
    "\n",
    "Este script utiliza Selenium y la librería Deep Face para detectar las caras de los participantes en una reunión de Zoom web y mostrar las emociones de la reunión.\n",
    "\n",
    "Para ello, el script abrirá una sesión de Chrome automatizada con Selenium, accederá a la reunión de Zoom utilizando la URL proporcionada, y luego utilizará Deep Face para analizar las expresiones faciales de los participantes.\n",
    "\n",
    "*(Podemos llegar a usar OpenCV para analizar, ademas de las emociones, los gestos corporales)*\n",
    "\n",
    "*Por ejemplo:*\n",
    "- Detección de Movimiento y Postura: Utilizar algoritmos de visión por computadora para detectar el movimiento de las personas y su postura durante la reunión. Un aumento en el movimiento o cambios en la postura pueden indicar un mayor nivel de interés o participación.\n",
    "- Reconocimiento de Gestos Faciales: Analizar los gestos faciales de los participantes para detectar sonrisas, fruncir el ceño, miradas de atención, entre otros.\n",
    "- Participación en la Conversación: Analizar la participación verbal de las personas en la reunión, como la cantidad de tiempo que hablan, la frecuencia con la que hacen preguntas o comentarios, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librerías necesarias\n",
    "\n",
    "- pip install selenium\n",
    "- pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerias necesarias\n",
    "\n",
    "from selenium import webdriver\n",
    "from deepface import DeepFace\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_screenshot(driver, filename='screenshot.png'):\n",
    "    driver.save_screenshot(filename)\n",
    "\n",
    "def analyze_emotion(image_path='screenshot.png'):\n",
    "    img = cv2.imread(image_path)\n",
    "    return DeepFace.analyze(img, actions=['emotion'])\n",
    "\n",
    "def compute_engagement(emotion_results):\n",
    "    engagement_scores = {\n",
    "        'happy': 1,\n",
    "        'surprise': 1,\n",
    "        'neutral': 0.5,\n",
    "        'sad': -1,\n",
    "        'angry': -1,\n",
    "        'fear': -1,\n",
    "        'disgust': -1\n",
    "    }\n",
    "    \n",
    "    total_score = 0\n",
    "    for res in emotion_results:\n",
    "        dominant_emotion = res['dominant_emotion']\n",
    "        total_score += engagement_scores.get(dominant_emotion, 0)\n",
    "    \n",
    "    return total_score / len(emotion_results)\n",
    "\n",
    "# Initialize WebDriver\n",
    "driver = webdriver.Chrome(executable_path='./chromedriver')\n",
    "driver.get(\"https://zoom.us/wc/join/<meeting-id>\")\n",
    "time.sleep(30)  # Adjust based on when the meeting starts\n",
    "\n",
    "while True:\n",
    "    capture_screenshot(driver)\n",
    "    emotion_result = analyze_emotion()\n",
    "    engagement_score = compute_engagement([emotion_result])\n",
    "    print(f\"General Engagement Score: {engagement_score}\")\n",
    "    time.sleep(60)  # Capture screenshot every minute\n",
    "\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
